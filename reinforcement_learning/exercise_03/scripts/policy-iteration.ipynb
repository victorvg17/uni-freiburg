{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import sys\n",
    "from gridworld import GridworldEnv\n",
    "import policy_iteration\n",
    "import value_iteration\n",
    "\n",
    "def setUpModule():\n",
    "    global env\n",
    "    env = GridworldEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob: 1.0, next_s:0, reward: -1.0, done:True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1.0, 0, -1.0, True)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = GridworldEnv()\n",
    "[(prob, next_s, reward, done)] = env.P[1][3]\n",
    "fu1 = env.P[1][3]\n",
    "np.shape(fu1), fu1\n",
    "print(f'prob: {prob}, next_s:{next_s}, reward: {reward}, done:{done}')\n",
    "fu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPolicyEval(unittest.TestCase):\n",
    "    def test_policy_eval(self):\n",
    "        random_policy = np.ones([env.nS, env.nA]) / env.nA\n",
    "        v = policy_iteration.policy_eval(random_policy, env)\n",
    "        expected_v = np.array([0, -14, -20, -22, -14, -18, -20, -20, -20, -20, -18, -14, -22, -20, -14, 0])\n",
    "        np.testing.assert_array_almost_equal(v, expected_v, decimal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestIterationAlgorithm:\n",
    "    def test_policy(self):\n",
    "        expected_policy = [[1., 0., 0., 0.],\n",
    "                           [0., 0., 0., 1.],\n",
    "                           [0., 0., 0., 1.],\n",
    "                           [0., 0., 1., 0.],\n",
    "                           [1., 0., 0., 0.],\n",
    "                           [1., 0., 0., 0.],\n",
    "                           [1., 0., 0., 0.],\n",
    "                           [0., 0., 1., 0.],\n",
    "                           [1., 0., 0., 0.],\n",
    "                           [1., 0., 0., 0.],\n",
    "                           [0., 1., 0., 0.],\n",
    "                           [0., 0., 1., 0.],\n",
    "                           [1., 0., 0., 0.],\n",
    "                           [0., 1., 0., 0.],\n",
    "                           [0., 1., 0., 0.],\n",
    "                           [1., 0., 0., 0.]]\n",
    "        np.testing.assert_array_equal(self.policy, expected_policy)\n",
    "    def test_value(self):\n",
    "        expected_v = np.array([0, -1, -2, -3, -1, -2, -3, -2, -2, -3, -2, -1, -3, -2, -1,  0])\n",
    "        np.testing.assert_array_almost_equal(self.v, expected_v, decimal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPolicyImprovement(unittest.TestCase, TestIterationAlgorithm):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.policy, cls.v = policy_iteration.policy_improvement(env)\n",
    "\n",
    "class TestValueIteration(unittest.TestCase, TestIterationAlgorithm):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.policy, cls.v = value_iteration.value_iteration(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fu1 = np.max([3, 4, 5, 6])\n",
    "fu1 = max(3, 4, 5, 6)\n",
    "fu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: /run/user/1000/jupyter/kernel-675027e1-2579-4761-a294-792b8e7122d8 (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute '/run/user/1000/jupyter/kernel-675027e1-2579-4761-a294-792b8e7122d8'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
